{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook I implement a U-Net model with less than 90,000 parameters. The model makes use of inverted residual blocks as the main processing blocks of the models and employs pyramid scene parsing in the 'horizontal' connections of U-Net. The training is not carried out in this notebook, weights from previous training sessions are loaded in. The model is pretrained on the LIVECell dataset [(https://www.nature.com/articles/s41592-021-01249-6)](https://www.nature.com/articles/s41592-021-01249-6) for 8 epochs.\n",
    "\n",
    "Solarized dark             |  Solarized Ocean\n",
    ":-------------------------:|:-------------------------:\n",
    "![alt](__results___8_2.png) | ![__results___10_1.png](__results___10_1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-18T19:57:05.306423Z",
     "iopub.status.busy": "2022-04-18T19:57:05.306012Z",
     "iopub.status.idle": "2022-04-18T19:57:12.251945Z",
     "shell.execute_reply": "2022-04-18T19:57:12.250982Z",
     "shell.execute_reply.started": "2022-04-18T19:57:05.306319Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:57:12.253878Z",
     "iopub.status.busy": "2022-04-18T19:57:12.253627Z",
     "iopub.status.idle": "2022-04-18T19:57:12.274520Z",
     "shell.execute_reply": "2022-04-18T19:57:12.273440Z",
     "shell.execute_reply.started": "2022-04-18T19:57:12.253848Z"
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Defining the blocks which make up the model\n",
    "###\n",
    "\n",
    "def inverted_residual_block(x, expand=64, squeeze=16):\n",
    "    m = keras.layers.Conv2D(expand, 1, padding='same')(x)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    m = keras.layers.Activation('relu')(m)\n",
    "    \n",
    "    m = keras.layers.DepthwiseConv2D(3, padding='same')(m)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    m = keras.layers.Activation('relu')(m)\n",
    "    \n",
    "    m = keras.layers.Conv2D(squeeze, 1, padding='same')(m)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    m = keras.layers.Activation('relu')(m)\n",
    "    \n",
    "    return keras.layers.add([m, x])\n",
    "\n",
    "def down_sampling_block(x,filters):\n",
    "    m = keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    # project residual\n",
    "    # residuals are projected by running a 2D convolution with stride 2 \n",
    "    # which are then added to the output of the MaxPooling layer as a residual.\n",
    "    r = keras.layers.Conv2D(filters, 1, strides=2, padding='same')(x)\n",
    "    r = keras.layers.BatchNormalization()(r)\n",
    "    r = keras.layers.Activation('relu')(r)\n",
    "    return keras.layers.add([m, r])\n",
    "\n",
    "def up_sampling_block(x, filters):\n",
    "    m = keras.layers.UpSampling2D(2)(x)\n",
    "    # project residual\n",
    "    # residuals are projected by running a 2D convolution with stride 2 \n",
    "    # which are then added to the output of the MaxPooling layer as a residual.\n",
    "    r = keras.layers.UpSampling2D(2)(x)\n",
    "    r = keras.layers.Conv2D(filters, 1, padding='same')(r)\n",
    "    r = keras.layers.BatchNormalization()(r)\n",
    "    r = keras.layers.Activation('relu')(r)\n",
    "    return keras.layers.add([m, r])\n",
    "\n",
    "\n",
    "def pyramid_parsing(x, depth=0, img_size=(520, 704),\n",
    "                    filters=8, f_ratio=8, pyramid=[2,3,6,9]):\n",
    "    HEIGHT, WIDTH = img_size\n",
    "    HEIGHT, WIDTH = HEIGHT // 2**depth, WIDTH // 2**depth # the model down samples by 2 for each layer of given 'depth'\n",
    "        \n",
    "    y = x\n",
    "    for bin_val in pyramid:\n",
    "        \n",
    "        m = keras.layers.MaxPool2D(pool_size=(HEIGHT//bin_val, WIDTH//bin_val),\n",
    "                                   padding='same')(x)\n",
    "        # check if the bin size is larger due to the padding\n",
    "        m_HEIGHT, m_WIDTH = m.get_shape()[1:3]\n",
    "\n",
    "            \n",
    "        m = keras.layers.UpSampling2D(size=(HEIGHT//m_HEIGHT, WIDTH//m_WIDTH))(m)\n",
    "        # as it stands, with proper use of flooring values and calling the bins, \n",
    "        # the layers (if they do not match perfectly) are slightly undersized by several pixels. \n",
    "        # resize allows to use nearest neighbor interpolation to extend the edge bins inplace of zero padding. \n",
    "        m = keras.layers.Resizing(HEIGHT, WIDTH, interpolation='nearest')(m)\n",
    "        \n",
    "        \n",
    "        # scale down the amount of filters\n",
    "        m = keras.layers.Conv2D(filters//f_ratio, 1, padding='same')(m)\n",
    "        m = keras.layers.BatchNormalization()(m)\n",
    "        m = keras.layers.Activation('relu')(m)\n",
    "        y = keras.layers.Concatenate()([y, m])\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:57:12.276771Z",
     "iopub.status.busy": "2022-04-18T19:57:12.276460Z",
     "iopub.status.idle": "2022-04-18T19:57:12.301573Z",
     "shell.execute_reply": "2022-04-18T19:57:12.300739Z",
     "shell.execute_reply.started": "2022-04-18T19:57:12.276729Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(img_size, channels, num_classes, filter_list = [8, 16, 32, 64], PSP=False):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Creates the U-net model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_size: tuple\n",
    "        The dimensions of the input samples (x,y)\n",
    "    channels: int\n",
    "        The channels of the input samples\n",
    "    filter_list: list\n",
    "        A list of the desired filters to construct the model with. The length of the list defines the depth of the model,\n",
    "        with the final value being the 'bottom' layer.\n",
    "    num_classes: int\n",
    "        The amount of desired output channels.\n",
    "    PSP: bool\n",
    "        Defines if the model should use Pyramid Scene Parsing in its layers.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tf.keras Functional API model, samples have shape of (img_size[0], img_size[1], num_classes.)\n",
    "    \n",
    "    \"\"\"\n",
    "    max_filter = filter_list[-1]\n",
    "    filter_list = filter_list[:-1]\n",
    "    \n",
    "    \n",
    "    inputs = keras.Input(shape=img_size + (channels,))\n",
    "    x = inputs # redefine for the loop\n",
    "\n",
    "    ### Downsampling layers ###\n",
    "    \n",
    "    horizontal_connections = [] # collect the outputs of layers to use in the horizontal connection of U-net\n",
    "    \n",
    "    depth = 0\n",
    "    # Used in pyramid parsing\n",
    "    # for repeating halfing of size\n",
    "    # 2**depth\n",
    "    \n",
    "    for filters in filter_list:\n",
    "        # point wise convolution to expand filters. \n",
    "        x = keras.layers.Conv2D(filters, 1, padding='same')(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        \n",
    "        x = inverted_residual_block(x, expand=filters*2, squeeze=filters)\n",
    "        x = inverted_residual_block(x, expand=filters*2, squeeze=filters)\n",
    "\n",
    "        \n",
    "        if PSP:\n",
    "            context_stack = pyramid_parsing(x, depth=depth, img_size=img_size,\n",
    "                                        filters=filters, f_ratio=filters)\n",
    "            horizontal_connections.append(context_stack)\n",
    "            depth += 1\n",
    "        \n",
    "        else:\n",
    "            horizontal_connections.append(x)\n",
    "        \n",
    "        x = down_sampling_block(x,filters=filters)\n",
    "        \n",
    "        \n",
    "    ### Bottom layer ### \n",
    "    # no horizontal connection\n",
    "    bottom_filter = max_filter\n",
    "    x = keras.layers.Conv2D(bottom_filter, 1, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    x = inverted_residual_block(x, expand=bottom_filter*2, squeeze=bottom_filter)\n",
    "    x = inverted_residual_block(x, expand=bottom_filter*2, squeeze=bottom_filter)\n",
    "        \n",
    "    ### Upsampling layers ###\n",
    "\n",
    "        \n",
    "    for filters, h_con in zip(filter_list[::-1], horizontal_connections[::-1]):\n",
    "        # upsample, add the horizontal components\n",
    "        x = up_sampling_block(x, filters=filters*2)\n",
    "        x = keras.layers.Concatenate()([x,h_con])\n",
    "        \n",
    "\n",
    "        # shrink filters to desired size\n",
    "        x = keras.layers.Conv2D(filters, 1, padding='same')(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "        \n",
    "        x = inverted_residual_block(x, expand=filters*2, squeeze=filters)\n",
    "        x = inverted_residual_block(x, expand=filters*2, squeeze=filters)\n",
    "        \n",
    "        \n",
    "        \n",
    "     # Add a per-pixel classification layer\n",
    "\n",
    "    x = keras.layers.Conv2D(num_classes, 3, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    outputs = keras.layers.Activation('sigmoid')(x)\n",
    "    \n",
    "\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:57:12.304609Z",
     "iopub.status.busy": "2022-04-18T19:57:12.304233Z",
     "iopub.status.idle": "2022-04-18T19:57:15.855593Z",
     "shell.execute_reply": "2022-04-18T19:57:15.854574Z",
     "shell.execute_reply.started": "2022-04-18T19:57:12.304565Z"
    }
   },
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 520, 704\n",
    "image_size = (HEIGHT, WIDTH)\n",
    "model = get_model(image_size, channels=1, num_classes=1, filter_list = [8, 16, 32, 64], PSP=True)\n",
    "model.load_weights('/kaggle/input/cell-model-weights/spyramid_8/spyramid_8_epoch') # load the weights from training\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Look at the mask performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:57:15.857079Z",
     "iopub.status.busy": "2022-04-18T19:57:15.856863Z",
     "iopub.status.idle": "2022-04-18T19:57:20.997755Z",
     "shell.execute_reply": "2022-04-18T19:57:20.996755Z",
     "shell.execute_reply.started": "2022-04-18T19:57:15.857053Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_files = ['../input/sartorius-cell-instance-segmentation/test/7ae19de7bc2a.png',\n",
    "               '../input/sartorius-cell-instance-segmentation/test/d48ec7815252.png',\n",
    "               '../input/sartorius-cell-instance-segmentation/test/d8bfd1dafdc4.png']\n",
    "\n",
    "\n",
    "for file_path in sample_files:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,16), sharey=True)\n",
    "\n",
    "    input_test = plt.imread(str(file_path)).reshape(1, 520, 704, 1)\n",
    "    input_test = (input_test) - np.mean(input_test) # \n",
    "    \n",
    "    pred = model.predict(input_test) \n",
    "    \n",
    "    ax1.imshow(input_test[0])\n",
    "    ax2.imshow(pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, the model can actually select out the cells present in the sample. If one wanted to simply select all cells in an image, this is not a bad masker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Mask output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:57:20.999238Z",
     "iopub.status.busy": "2022-04-18T19:57:20.999009Z",
     "iopub.status.idle": "2022-04-18T19:57:22.594891Z",
     "shell.execute_reply": "2022-04-18T19:57:22.593831Z",
     "shell.execute_reply.started": "2022-04-18T19:57:20.999202Z"
    }
   },
   "outputs": [],
   "source": [
    "import skimage.morphology\n",
    "\n",
    "############ Submission\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array. \n",
    "        1 - mask, 0 - background\n",
    "        \n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def get_regions(x, THRESHOLD, min_size=25):\n",
    "    \"\"\"\n",
    "    Converts predictions to rle encoded masks.\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    x: numpy array\n",
    "        Predictions from our model.\n",
    "    THRESHOLD: float\n",
    "        The threshold value were we consider a pixel a cell.\n",
    "    min_size: int\n",
    "        The minimum size (length) of a mask to be included in our final output.\n",
    "        \n",
    "    Returns\n",
    "    --------------\n",
    "    res: list\n",
    "        list of masks encoded into rle encodings. \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    regions = skimage.morphology.label(x>THRESHOLD) # select out seperate regions.\n",
    "    for i in range(1, regions.max() +1):\n",
    "        rle = rle_encode(regions==i)\n",
    "        if len(rle) >= min_size: # skip predictions with small area\n",
    "#             print(len(rle))\n",
    "            res.append(rle)\n",
    "        else:\n",
    "            continue\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:57:22.596614Z",
     "iopub.status.busy": "2022-04-18T19:57:22.596134Z",
     "iopub.status.idle": "2022-04-18T19:57:24.010482Z",
     "shell.execute_reply": "2022-04-18T19:57:24.009421Z",
     "shell.execute_reply.started": "2022-04-18T19:57:22.596568Z"
    }
   },
   "outputs": [],
   "source": [
    "test_files = glob('../input/sartorius-cell-instance-segmentation/test/*') # grab all test files\n",
    "\n",
    "sample_submission = pd.read_csv('../input/sartorius-cell-instance-segmentation/sample_submission.csv')\n",
    "output_df = pd.DataFrame(data = None, columns = sample_submission.columns)\n",
    "\n",
    "\n",
    "count = 0 # running count to idx the output df\n",
    "\n",
    "### Loop over all test files ###\n",
    "for file_path in test_files:\n",
    "    tag = file_path.split('/')[-1][:-4] # splits the sample name off from the filepath\n",
    "    print(tag)\n",
    "    input_test = plt.imread(str(file_path)).reshape(1, 520, 704, 1) # extra channel in the front so easy input into the model.\n",
    "    input_test = (input_test) - np.mean(input_test) # zero center the data\n",
    "\n",
    "    pred = model.predict(input_test)\n",
    "    regions = get_regions(pred[0], 0.5, min_size=25)\n",
    "    \n",
    "    \n",
    "    for mask in regions:\n",
    "        output_df.loc[count] = tag, mask\n",
    "        count+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:57:24.013744Z",
     "iopub.status.busy": "2022-04-18T19:57:24.013395Z",
     "iopub.status.idle": "2022-04-18T19:57:24.030131Z",
     "shell.execute_reply": "2022-04-18T19:57:24.029234Z",
     "shell.execute_reply.started": "2022-04-18T19:57:24.013696Z"
    }
   },
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:57:24.031597Z",
     "iopub.status.busy": "2022-04-18T19:57:24.031378Z",
     "iopub.status.idle": "2022-04-18T19:57:24.045464Z",
     "shell.execute_reply": "2022-04-18T19:57:24.044633Z",
     "shell.execute_reply.started": "2022-04-18T19:57:24.031571Z"
    }
   },
   "outputs": [],
   "source": [
    "output_df.to_csv('/kaggle/working/submission.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
